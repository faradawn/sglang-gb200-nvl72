+ echo '=== 11-30 low precision prefill SLURM_NODEID 9'
=== 11-30 low precision prefill SLURM_NODEID 9
+ export SGLANG_HEALTH_CHECK_TIMEOUT=3600
+ SGLANG_HEALTH_CHECK_TIMEOUT=3600
+ [[ 9 -lt 1 ]]
+ export TORCH_DISTRIBUTED_DEFAULT_TIMEOUT=1800
+ TORCH_DISTRIBUTED_DEFAULT_TIMEOUT=1800
+ node_rank=8
+ export SGLANG_TORCH_PROFILER_DIR=/base_dir/../decode_torch_profiler
+ SGLANG_TORCH_PROFILER_DIR=/base_dir/../decode_torch_profiler
+ mkdir -p /base_dir/../decode_torch_profiler
+ export SGLANG_DUMPER_DIR=/base_dir/../decode_sglang_dump
+ SGLANG_DUMPER_DIR=/base_dir/../decode_sglang_dump
+ mkdir -p /base_dir/../decode_sglang_dump
+ export SGLANG_EXPERT_DISTRIBUTION_RECORDER_DIR=/base_dir/../decode_sglang_expert_distribution_recorder
+ SGLANG_EXPERT_DISTRIBUTION_RECORDER_DIR=/base_dir/../decode_sglang_expert_distribution_recorder
+ mkdir -p /base_dir/../decode_sglang_expert_distribution_recorder
+ export FLASHINFER_WORKSPACE_BASE=/base_dir/../decode_flashinfer_workspace_base
+ FLASHINFER_WORKSPACE_BASE=/base_dir/../decode_flashinfer_workspace_base
+ mkdir -p /base_dir/../decode_flashinfer_workspace_base
+ export SGL_DG_CACHE_DIR=/base_dir/../decode_deepgemm_cache
+ SGL_DG_CACHE_DIR=/base_dir/../decode_deepgemm_cache
+ mkdir -p /base_dir/../decode_deepgemm_cache
+ SERVER_PID=1800309
+ DYN_SKIP_SGLANG_LOG_FORMATTING=1
+ [[ 9 -eq 0 ]]
+ SGLANG_NVFP4_CKPT_FP8_GEMM_IN_ATTN=1
+ wait 1800309
+ SGLANG_PER_TOKEN_GROUP_QUANT_8BIT_V2=1
+ SGL_JIT_DEEPGEMM_PRECOMPILE=0
+ SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=1024
+ SGLANG_CUTEDSL_MOE_NVFP4_DISPATCH=1
+ SGLANG_FP4_GEMM_BACKEND=cutlass
+ MC_TE_METRIC=true
+ SGLANG_DISAGGREGATION_HEARTBEAT_MAX_FAILURE=100000
+ SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=100000
+ SGLANG_DISAGGREGATION_WAITING_TIMEOUT=100000
+ SGLANG_HACK_SEQ_BOOTSTRAP_ROOM=1
+ SGLANG_MOONCAKE_CUSTOM_MEM_POOL=True
+ MC_FORCE_MNNVL=1
+ NCCL_MNNVL_ENABLE=1
+ NCCL_CUMEM_ENABLE=1
+ SGLANG_USE_MESSAGE_QUEUE_BROADCASTER=0
+ SGLANG_DISABLE_TP_MEMORY_INBALANCE_CHECK=1
+ PYTHONUNBUFFERED=1
+ python3 -m sglang.launch_server --model-path nvidia/DeepSeek-R1-0528-FP4 --trust-remote-code --disaggregation-mode decode --dist-init-addr 10.52.103.108:20000 --dist-timeout 3600 --disaggregation-bootstrap-port 30001 --nnodes 12 --node-rank 8 --tp-size 48 --dp-size 48 --ep-size 48 --enable-dp-attention --host 0.0.0.0 --port 30000 --decode-log-interval 1 --max-running-requests 49152 --context-length 4224 --disable-radix-cache --disable-shared-experts-fusion --watchdog-timeout 1000000 --disable-chunked-prefix-cache --kv-cache-dtype fp8_e4m3 --enable-single-batch-overlap --mem-fraction-static 0.83 --moe-a2a-backend deepep --deepep-mode low_latency --ep-dispatch-algorithm static --cuda-graph-bs 1024 --num-reserved-decode-tokens 112 --ep-num-redundant-experts 32 --eplb-algorithm deepseek --moe-dense-tp-size 1 --enable-dp-lm-head --prefill-round-robin-balance --max-total-tokens 3122380 --max-prefill-tokens 16384 --quantization modelopt_fp4 --moe-runner-backend flashinfer_cutedsl
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_JIT_DEEPGEMM_PRECOMPILE is deprecated, please use SGLANG_JIT_DEEPGEMM_PRECOMPILE
  warnings.warn(
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_DG_CACHE_DIR is deprecated, please use SGLANG_DG_CACHE_DIR
  warnings.warn(
[2025-11-30 07:42:49] INFO server_args.py:941: Use trtllm_mla as attention backend on sm100 for DeepseekV3ForCausalLM
[2025-11-30 07:42:50] WARNING server_args.py:1329: TensorRT-LLM MLA only supports page_size of 32 or 64, changing page_size from None to 64.
[2025-11-30 07:42:50] WARNING server_args.py:1453: DP attention is enabled. The chunked prefill size is adjusted to 341 to avoid MoE kernel issues. 
[2025-11-30 07:42:50] WARNING server_args.py:1502: DeepEP MoE is enabled. The expert parallel size is adjusted to be the same as the tensor parallel size[48].
[2025-11-30 07:42:50] WARNING server_args.py:1770: KV cache is forced as chunk cache for decode server
[2025-11-30 07:42:50] server_args=ServerArgs(model_path='nvidia/DeepSeek-R1-0528-FP4', tokenizer_path='nvidia/DeepSeek-R1-0528-FP4', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=4224, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=30000, fastapi_root_path='', grpc_mode=False, skip_server_warmup=False, warmups=None, nccl_port=None, checkpoint_engine_wait_weights_before_ready=False, dtype='auto', quantization='modelopt_fp4', quantization_param_path=None, kv_cache_dtype='fp8_e4m3', enable_fp32_lm_head=False, modelopt_quant=None, modelopt_checkpoint_restore_path=None, modelopt_checkpoint_save_path=None, modelopt_export_path=None, quantize_and_serve=False, mem_fraction_static=0.83, max_running_requests=49152, max_queued_requests=None, max_total_tokens=3122380, chunked_prefill_size=341, max_prefill_tokens=16384, schedule_policy='fcfs', enable_priority_scheduling=False, abort_on_priority_when_disabled=False, schedule_low_priority_values_first=False, priority_scheduling_preemption_threshold=10, schedule_conservativeness=0.3, page_size=64, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, radix_eviction_policy='lru', device='cuda', tp_size=48, pp_size=1, pp_max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=506458774, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=1000000.0, dist_timeout=3600, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, mm_process_config={}, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-custom-labels', tokenizer_metrics_allowed_custom_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, gc_warning_threshold_secs=0.0, decode_log_interval=1, enable_request_time_stats_logging=False, kv_events_config=None, enable_trace=False, otlp_traces_endpoint='localhost:4317', export_metrics_to_file=False, export_metrics_to_file_dir=None, api_key=None, served_model_name='nvidia/DeepSeek-R1-0528-FP4', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, sampling_defaults='model', dp_size=48, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=True, dist_init_addr='10.52.103.108:20000', nnodes=12, node_rank=8, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', lora_backend='csgmv', max_lora_chunk_size=16, attention_backend='trtllm_mla', decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, nsa_prefill_backend='flashmla_sparse', nsa_decode_backend='fa3', speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_draft_load_format=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', speculative_moe_runner_backend=None, speculative_ngram_min_match_window_size=1, speculative_ngram_max_match_window_size=12, speculative_ngram_min_bfs_breadth=1, speculative_ngram_max_bfs_breadth=10, speculative_ngram_match_type='BFS', speculative_ngram_branch_length=18, speculative_ngram_capacity=10000000, ep_size=48, moe_a2a_backend='deepep', moe_runner_backend='flashinfer_cutedsl', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='low_latency', ep_num_redundant_experts=32, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='deepseek', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=1, elastic_ep_backend=None, mooncake_ib_device=None, max_mamba_cache_size=None, mamba_ssm_dtype='float32', mamba_full_memory_ratio=0.9, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, kt_weight_path=None, kt_method='AMXINT4', kt_cpuinfer=None, kt_threadpool_count=2, kt_num_gpu_experts=None, kt_max_deferred_experts_per_token=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', multi_item_scoring_delimiter=None, disable_radix_cache=True, cuda_graph_max_bs=1024, cuda_graph_bs=[1024], disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_layerwise_nvtx_marker=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_tokenizer_batch_decode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, enable_torch_symm_mem=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=True, enable_dp_lm_head=True, enable_two_batch_overlap=False, enable_single_batch_overlap=True, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, enable_piecewise_cuda_graph=False, torch_compile_max_bs=32, piecewise_cuda_graph_max_tokens=4096, piecewise_cuda_graph_tokens=[4, 8, 12, 16, 20, 24, 28, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048, 2176, 2304, 2432, 2560, 2688, 2816, 2944, 3072, 3200, 3328, 3456, 3584, 3712, 3840, 3968, 4096], piecewise_cuda_graph_compiler='eager', torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, enable_weights_cpu_backup=False, enable_draft_weights_cpu_backup=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=True, disable_chunked_prefix_cache=True, disable_fast_image_processor=False, keep_mm_feature_on_device=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_deterministic_inference=False, rl_on_policy_target=None, enable_attn_tp_input_scattered=False, enable_nsa_prefill_context_parallel=False, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_layers=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='decode', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=30001, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, disaggregation_decode_enable_offload_kvcache=False, num_reserved_decode_tokens=112, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, enable_pdmux=False, pdmux_config_path=None, sm_group_num=8, mm_max_concurrent_calls=32, mm_per_request_timeout=10.0, enable_broadcast_mm_inputs_process=False, decrypted_config_file=None, decrypted_draft_config_file=None, mm_enable_dp_encoder=False, hooks=None)
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_JIT_DEEPGEMM_PRECOMPILE is deprecated, please use SGLANG_JIT_DEEPGEMM_PRECOMPILE
  warnings.warn(
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_DG_CACHE_DIR is deprecated, please use SGLANG_DG_CACHE_DIR
  warnings.warn(
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_JIT_DEEPGEMM_PRECOMPILE is deprecated, please use SGLANG_JIT_DEEPGEMM_PRECOMPILE
  warnings.warn(
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_DG_CACHE_DIR is deprecated, please use SGLANG_DG_CACHE_DIR
  warnings.warn(
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_JIT_DEEPGEMM_PRECOMPILE is deprecated, please use SGLANG_JIT_DEEPGEMM_PRECOMPILE
  warnings.warn(
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_DG_CACHE_DIR is deprecated, please use SGLANG_DG_CACHE_DIR
  warnings.warn(
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_JIT_DEEPGEMM_PRECOMPILE is deprecated, please use SGLANG_JIT_DEEPGEMM_PRECOMPILE
  warnings.warn(
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_JIT_DEEPGEMM_PRECOMPILE is deprecated, please use SGLANG_JIT_DEEPGEMM_PRECOMPILE
  warnings.warn(
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_DG_CACHE_DIR is deprecated, please use SGLANG_DG_CACHE_DIR
  warnings.warn(
/sgl-workspace/sglang/python/sglang/srt/environ.py:337: UserWarning: Environment variable SGL_DG_CACHE_DIR is deprecated, please use SGLANG_DG_CACHE_DIR
  warnings.warn(
[2025-11-30 07:43:04 DP35 TP35 EP35] Init torch distributed begin.
[2025-11-30 07:43:04 DP32 TP32 EP32] Init torch distributed begin.
[2025-11-30 07:43:05 DP33 TP33 EP33] Init torch distributed begin.
[2025-11-30 07:43:05 DP34 TP34 EP34] Init torch distributed begin.
[Gloo] Rank [Gloo] Rank [Gloo] Rank 3233[Gloo] Rank 34 is connected to  is connected to 35 is connected to 4747 is connected to 47 peer ranks.  peer ranks. 47 peer ranks. Expected number of connected peer ranks is : Expected number of connected peer ranks is :  peer ranks. Expected number of connected peer ranks is : 4747Expected number of connected peer ranks is : 47

47

[Gloo] Rank 32 is connected to 47 peer ranks. Expected number of connected peer ranks is : 47
[Gloo] Rank [Gloo] Rank 34[Gloo] Rank 33 is connected to 35 is connected to 47 is connected to 47 peer ranks. 47 peer ranks. Expected number of connected peer ranks is :  peer ranks. Expected number of connected peer ranks is : 47Expected number of connected peer ranks is : 47
47

[2025-11-30 07:43:08 DP35 TP35 EP35] Custom allreduce is disabled because this process group spans across nodes.
[2025-11-30 07:43:08 DP34 TP34 EP34] Custom allreduce is disabled because this process group spans across nodes.
[2025-11-30 07:43:08 DP33 TP33 EP33] Custom allreduce is disabled because this process group spans across nodes.
[2025-11-30 07:43:08 DP32 TP32 EP32] Custom allreduce is disabled because this process group spans across nodes.
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2025-11-30 07:43:08 DP35 TP35 EP35] Init torch distributed ends. mem usage=1.07 GB
[2025-11-30 07:43:08 DP34 TP34 EP34] Init torch distributed ends. mem usage=1.07 GB
[2025-11-30 07:43:08 DP33 TP33 EP33] Init torch distributed ends. mem usage=1.07 GB
[2025-11-30 07:43:08 DP32 TP32 EP32] Init torch distributed ends. mem usage=1.07 GB
[2025-11-30 07:43:09 DP32 TP32 EP32] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-11-30 07:43:09 DP33 TP33 EP33] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-11-30 07:43:09 DP34 TP34 EP34] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-11-30 07:43:09 DP35 TP35 EP35] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-11-30 07:43:13 DP32 TP32 EP32] Load weight begin. avail mem=182.19 GB
[2025-11-30 07:43:13 DP32 TP32 EP32] Using ModelOptModelLoader due to ModelOpt quantization config.
[2025-11-30 07:43:13 DP32 TP32 EP32] ModelOptModelLoader: Loading base model...
[2025-11-30 07:43:13 DP33 TP33 EP33] Load weight begin. avail mem=182.19 GB
[2025-11-30 07:43:13 DP33 TP33 EP33] Using ModelOptModelLoader due to ModelOpt quantization config.
[2025-11-30 07:43:13 DP33 TP33 EP33] ModelOptModelLoader: Loading base model...
[2025-11-30 07:43:13 DP32 TP32 EP32] Model is already quantized, loading directly...
[2025-11-30 07:43:13 DP33 TP33 EP33] Model is already quantized, loading directly...
[2025-11-30 07:43:13 DP35 TP35 EP35] Load weight begin. avail mem=182.18 GB
[2025-11-30 07:43:13 DP35 TP35 EP35] Using ModelOptModelLoader due to ModelOpt quantization config.
[2025-11-30 07:43:13 DP35 TP35 EP35] ModelOptModelLoader: Loading base model...
[2025-11-30 07:43:13 DP34 TP34 EP34] Load weight begin. avail mem=182.19 GB
[2025-11-30 07:43:13 DP34 TP34 EP34] Using ModelOptModelLoader due to ModelOpt quantization config.
[2025-11-30 07:43:13 DP34 TP34 EP34] ModelOptModelLoader: Loading base model...
[2025-11-30 07:43:13 DP32 TP32 EP32] Detected nvfp4 checkpoint. Please note that the format is experimental and subject to change.
[2025-11-30 07:43:13 DP35 TP35 EP35] Model is already quantized, loading directly...
[2025-11-30 07:43:13 DP34 TP34 EP34] Model is already quantized, loading directly...
[2025-11-30 07:43:13 DP33 TP33 EP33] Detected nvfp4 checkpoint. Please note that the format is experimental and subject to change.
[2025-11-30 07:43:14 DP35 TP35 EP35] Detected nvfp4 checkpoint. Please note that the format is experimental and subject to change.
[2025-11-30 07:43:14 DP34 TP34 EP34] Detected nvfp4 checkpoint. Please note that the format is experimental and subject to change.
quant attn to fp8 ue8m0:   0%|          | 0/61 [00:00<?, ?it/s]quant attn to fp8 ue8m0:   0%|          | 0/61 [00:00<?, ?it/s]quant attn to fp8 ue8m0:   0%|          | 0/61 [00:00<?, ?it/s]quant attn to fp8 ue8m0:   0%|          | 0/61 [00:00<?, ?it/s]quant attn to fp8 ue8m0:   2%|▏         | 1/61 [00:00<00:06,  9.46it/s]quant attn to fp8 ue8m0:   2%|▏         | 1/61 [00:00<00:06,  9.39it/s]quant attn to fp8 ue8m0:   2%|▏         | 1/61 [00:00<00:06,  9.38it/s]quant attn to fp8 ue8m0:   2%|▏         | 1/61 [00:00<00:06,  9.36it/s]quant attn to fp8 ue8m0:   3%|▎         | 2/61 [00:00<00:06,  8.55it/s]quant attn to fp8 ue8m0:   3%|▎         | 2/61 [00:00<00:06,  8.57it/s]quant attn to fp8 ue8m0:   3%|▎         | 2/61 [00:00<00:06,  8.54it/s]quant attn to fp8 ue8m0:   3%|▎         | 2/61 [00:00<00:06,  8.52it/s]quant attn to fp8 ue8m0:   5%|▍         | 3/61 [00:00<00:06,  8.63it/s]quant attn to fp8 ue8m0:   5%|▍         | 3/61 [00:00<00:06,  8.63it/s]quant attn to fp8 ue8m0:   5%|▍         | 3/61 [00:00<00:06,  8.62it/s]quant attn to fp8 ue8m0:   5%|▍         | 3/61 [00:00<00:06,  8.60it/s]quant attn to fp8 ue8m0:   7%|▋         | 4/61 [00:00<00:06,  8.87it/s]quant attn to fp8 ue8m0:   7%|▋         | 4/61 [00:00<00:06,  8.84it/s]quant attn to fp8 ue8m0:   7%|▋         | 4/61 [00:00<00:06,  8.84it/s]quant attn to fp8 ue8m0:   7%|▋         | 4/61 [00:00<00:06,  8.84it/s]quant attn to fp8 ue8m0:   8%|▊         | 5/61 [00:00<00:06,  8.95it/s]quant attn to fp8 ue8m0:   8%|▊         | 5/61 [00:00<00:06,  8.95it/s]quant attn to fp8 ue8m0:   8%|▊         | 5/61 [00:00<00:06,  8.95it/s]quant attn to fp8 ue8m0:   8%|▊         | 5/61 [00:00<00:06,  8.94it/s]quant attn to fp8 ue8m0:  10%|▉         | 6/61 [00:00<00:06,  8.73it/s]quant attn to fp8 ue8m0:  10%|▉         | 6/61 [00:00<00:06,  8.72it/s]quant attn to fp8 ue8m0:  10%|▉         | 6/61 [00:00<00:06,  8.71it/s]quant attn to fp8 ue8m0:  10%|▉         | 6/61 [00:00<00:06,  8.71it/s]quant attn to fp8 ue8m0:  11%|█▏        | 7/61 [00:00<00:06,  8.66it/s]quant attn to fp8 ue8m0:  11%|█▏        | 7/61 [00:00<00:06,  8.67it/s]quant attn to fp8 ue8m0:  11%|█▏        | 7/61 [00:00<00:06,  8.66it/s]quant attn to fp8 ue8m0:  11%|█▏        | 7/61 [00:00<00:06,  8.66it/s]quant attn to fp8 ue8m0:  13%|█▎        | 8/61 [00:00<00:06,  8.80it/s]quant attn to fp8 ue8m0:  13%|█▎        | 8/61 [00:00<00:06,  8.80it/s]quant attn to fp8 ue8m0:  13%|█▎        | 8/61 [00:00<00:06,  8.80it/s]quant attn to fp8 ue8m0:  13%|█▎        | 8/61 [00:00<00:06,  8.79it/s]quant attn to fp8 ue8m0:  15%|█▍        | 9/61 [00:01<00:05,  8.69it/s]quant attn to fp8 ue8m0:  15%|█▍        | 9/61 [00:01<00:05,  8.69it/s]quant attn to fp8 ue8m0:  15%|█▍        | 9/61 [00:01<00:06,  8.66it/s]quant attn to fp8 ue8m0:  15%|█▍        | 9/61 [00:01<00:05,  8.68it/s]quant attn to fp8 ue8m0:  16%|█▋        | 10/61 [00:01<00:05,  8.71it/s]quant attn to fp8 ue8m0:  16%|█▋        | 10/61 [00:01<00:05,  8.70it/s]quant attn to fp8 ue8m0:  16%|█▋        | 10/61 [00:01<00:05,  8.69it/s]quant attn to fp8 ue8m0:  16%|█▋        | 10/61 [00:01<00:05,  8.68it/s]quant attn to fp8 ue8m0:  18%|█▊        | 11/61 [00:01<00:05,  8.92it/s]quant attn to fp8 ue8m0:  18%|█▊        | 11/61 [00:01<00:05,  8.91it/s]quant attn to fp8 ue8m0:  18%|█▊        | 11/61 [00:01<00:05,  8.91it/s]quant attn to fp8 ue8m0:  18%|█▊        | 11/61 [00:01<00:05,  8.91it/s]quant attn to fp8 ue8m0:  20%|█▉        | 12/61 [00:01<00:05,  8.95it/s]quant attn to fp8 ue8m0:  20%|█▉        | 12/61 [00:01<00:05,  8.94it/s]quant attn to fp8 ue8m0:  20%|█▉        | 12/61 [00:01<00:05,  8.94it/s]quant attn to fp8 ue8m0:  20%|█▉        | 12/61 [00:01<00:05,  8.93it/s]quant attn to fp8 ue8m0:  21%|██▏       | 13/61 [00:01<00:05,  8.92it/s]quant attn to fp8 ue8m0:  21%|██▏       | 13/61 [00:01<00:05,  8.90it/s]quant attn to fp8 ue8m0:  21%|██▏       | 13/61 [00:01<00:05,  8.90it/s]quant attn to fp8 ue8m0:  21%|██▏       | 13/61 [00:01<00:05,  8.89it/s]quant attn to fp8 ue8m0:  23%|██▎       | 14/61 [00:01<00:05,  9.13it/s]quant attn to fp8 ue8m0:  23%|██▎       | 14/61 [00:01<00:05,  9.13it/s]quant attn to fp8 ue8m0:  23%|██▎       | 14/61 [00:01<00:05,  9.13it/s]quant attn to fp8 ue8m0:  23%|██▎       | 14/61 [00:01<00:05,  9.12it/s]quant attn to fp8 ue8m0:  25%|██▍       | 15/61 [00:01<00:04,  9.30it/s]quant attn to fp8 ue8m0:  25%|██▍       | 15/61 [00:01<00:04,  9.30it/s]quant attn to fp8 ue8m0:  25%|██▍       | 15/61 [00:01<00:04,  9.29it/s]quant attn to fp8 ue8m0:  25%|██▍       | 15/61 [00:01<00:04,  9.28it/s]quant attn to fp8 ue8m0:  26%|██▌       | 16/61 [00:01<00:04,  9.25it/s]quant attn to fp8 ue8m0:  26%|██▌       | 16/61 [00:01<00:04,  9.23it/s]quant attn to fp8 ue8m0:  26%|██▌       | 16/61 [00:01<00:04,  9.22it/s]quant attn to fp8 ue8m0:  26%|██▌       | 16/61 [00:01<00:04,  9.23it/s]quant attn to fp8 ue8m0:  28%|██▊       | 17/61 [00:01<00:04,  9.41it/s]quant attn to fp8 ue8m0:  28%|██▊       | 17/61 [00:01<00:04,  9.41it/s]quant attn to fp8 ue8m0:  28%|██▊       | 17/61 [00:01<00:04,  9.40it/s]quant attn to fp8 ue8m0:  28%|██▊       | 17/61 [00:01<00:04,  9.39it/s]quant attn to fp8 ue8m0:  30%|██▉       | 18/61 [00:01<00:04,  9.44it/s]quant attn to fp8 ue8m0:  30%|██▉       | 18/61 [00:01<00:04,  9.43it/s]quant attn to fp8 ue8m0:  30%|██▉       | 18/61 [00:01<00:04,  9.42it/s]quant attn to fp8 ue8m0:  30%|██▉       | 18/61 [00:01<00:04,  9.41it/s]quant attn to fp8 ue8m0:  31%|███       | 19/61 [00:02<00:04,  9.59it/s]quant attn to fp8 ue8m0:  33%|███▎      | 20/61 [00:02<00:04,  9.67it/s]quant attn to fp8 ue8m0:  33%|███▎      | 20/61 [00:02<00:04,  9.68it/s]quant attn to fp8 ue8m0:  33%|███▎      | 20/61 [00:02<00:04,  9.69it/s]quant attn to fp8 ue8m0:  33%|███▎      | 20/61 [00:02<00:04,  9.66it/s]quant attn to fp8 ue8m0:  34%|███▍      | 21/61 [00:02<00:04,  9.49it/s]quant attn to fp8 ue8m0:  34%|███▍      | 21/61 [00:02<00:04,  9.48it/s]quant attn to fp8 ue8m0:  34%|███▍      | 21/61 [00:02<00:04,  9.46it/s]quant attn to fp8 ue8m0:  34%|███▍      | 21/61 [00:02<00:04,  9.48it/s]quant attn to fp8 ue8m0:  36%|███▌      | 22/61 [00:02<00:04,  9.51it/s]quant attn to fp8 ue8m0:  36%|███▌      | 22/61 [00:02<00:04,  9.49it/s]quant attn to fp8 ue8m0:  36%|███▌      | 22/61 [00:02<00:04,  9.51it/s]quant attn to fp8 ue8m0:  36%|███▌      | 22/61 [00:02<00:04,  9.50it/s]quant attn to fp8 ue8m0:  38%|███▊      | 23/61 [00:02<00:03,  9.60it/s]quant attn to fp8 ue8m0:  38%|███▊      | 23/61 [00:02<00:03,  9.59it/s]quant attn to fp8 ue8m0:  38%|███▊      | 23/61 [00:02<00:03,  9.58it/s]quant attn to fp8 ue8m0:  38%|███▊      | 23/61 [00:02<00:03,  9.58it/s]quant attn to fp8 ue8m0:  39%|███▉      | 24/61 [00:02<00:03,  9.27it/s]quant attn to fp8 ue8m0:  39%|███▉      | 24/61 [00:02<00:03,  9.26it/s]quant attn to fp8 ue8m0:  39%|███▉      | 24/61 [00:02<00:04,  9.22it/s]quant attn to fp8 ue8m0:  39%|███▉      | 24/61 [00:02<00:04,  9.25it/s]quant attn to fp8 ue8m0:  41%|████      | 25/61 [00:02<00:03,  9.32it/s]quant attn to fp8 ue8m0:  41%|████      | 25/61 [00:02<00:03,  9.31it/s]quant attn to fp8 ue8m0:  41%|████      | 25/61 [00:02<00:03,  9.32it/s]quant attn to fp8 ue8m0:  41%|████      | 25/61 [00:02<00:03,  9.31it/s]quant attn to fp8 ue8m0:  43%|████▎     | 26/61 [00:02<00:03,  9.45it/s]quant attn to fp8 ue8m0:  43%|████▎     | 26/61 [00:02<00:03,  9.43it/s]quant attn to fp8 ue8m0:  43%|████▎     | 26/61 [00:02<00:03,  9.44it/s]quant attn to fp8 ue8m0:  43%|████▎     | 26/61 [00:02<00:03,  9.43it/s]quant attn to fp8 ue8m0:  44%|████▍     | 27/61 [00:02<00:03,  9.59it/s]quant attn to fp8 ue8m0:  46%|████▌     | 28/61 [00:03<00:03,  9.64it/s]quant attn to fp8 ue8m0:  46%|████▌     | 28/61 [00:03<00:03,  9.63it/s]quant attn to fp8 ue8m0:  46%|████▌     | 28/61 [00:03<00:03,  9.62it/s]quant attn to fp8 ue8m0:  46%|████▌     | 28/61 [00:03<00:03,  9.62it/s]quant attn to fp8 ue8m0:  49%|████▉     | 30/61 [00:03<00:03,  9.68it/s]quant attn to fp8 ue8m0:  49%|████▉     | 30/61 [00:03<00:03,  9.68it/s]quant attn to fp8 ue8m0:  49%|████▉     | 30/61 [00:03<00:03,  9.68it/s]quant attn to fp8 ue8m0:  49%|████▉     | 30/61 [00:03<00:03,  9.67it/s]quant attn to fp8 ue8m0:  51%|█████     | 31/61 [00:03<00:03,  9.63it/s]quant attn to fp8 ue8m0:  51%|█████     | 31/61 [00:03<00:03,  9.63it/s]quant attn to fp8 ue8m0:  51%|█████     | 31/61 [00:03<00:03,  9.63it/s]quant attn to fp8 ue8m0:  51%|█████     | 31/61 [00:03<00:03,  9.63it/s]quant attn to fp8 ue8m0:  52%|█████▏    | 32/61 [00:03<00:03,  9.18it/s]quant attn to fp8 ue8m0:  52%|█████▏    | 32/61 [00:03<00:03,  9.22it/s]quant attn to fp8 ue8m0:  52%|█████▏    | 32/61 [00:03<00:03,  9.20it/s]quant attn to fp8 ue8m0:  52%|█████▏    | 32/61 [00:03<00:03,  9.20it/s]quant attn to fp8 ue8m0:  54%|█████▍    | 33/61 [00:03<00:03,  9.00it/s]quant attn to fp8 ue8m0:  54%|█████▍    | 33/61 [00:03<00:03,  9.03it/s]quant attn to fp8 ue8m0:  54%|█████▍    | 33/61 [00:03<00:03,  9.02it/s]quant attn to fp8 ue8m0:  54%|█████▍    | 33/61 [00:03<00:03,  9.02it/s]quant attn to fp8 ue8m0:  56%|█████▌    | 34/61 [00:03<00:03,  8.72it/s]quant attn to fp8 ue8m0:  56%|█████▌    | 34/61 [00:03<00:03,  8.69it/s]quant attn to fp8 ue8m0:  56%|█████▌    | 34/61 [00:03<00:03,  8.64it/s]quant attn to fp8 ue8m0:  56%|█████▌    | 34/61 [00:03<00:03,  8.69it/s]quant attn to fp8 ue8m0:  57%|█████▋    | 35/61 [00:03<00:03,  8.56it/s]quant attn to fp8 ue8m0:  57%|█████▋    | 35/61 [00:03<00:03,  8.53it/s]quant attn to fp8 ue8m0:  57%|█████▋    | 35/61 [00:03<00:03,  8.56it/s]quant attn to fp8 ue8m0:  57%|█████▋    | 35/61 [00:03<00:03,  8.56it/s]quant attn to fp8 ue8m0:  59%|█████▉    | 36/61 [00:03<00:02,  8.68it/s]quant attn to fp8 ue8m0:  59%|█████▉    | 36/61 [00:03<00:02,  8.67it/s]quant attn to fp8 ue8m0:  59%|█████▉    | 36/61 [00:03<00:02,  8.66it/s]quant attn to fp8 ue8m0:  59%|█████▉    | 36/61 [00:03<00:02,  8.64it/s]quant attn to fp8 ue8m0:  61%|██████    | 37/61 [00:04<00:02,  8.68it/s]quant attn to fp8 ue8m0:  61%|██████    | 37/61 [00:04<00:02,  8.69it/s]quant attn to fp8 ue8m0:  61%|██████    | 37/61 [00:04<00:02,  8.69it/s]quant attn to fp8 ue8m0:  61%|██████    | 37/61 [00:04<00:02,  8.68it/s]quant attn to fp8 ue8m0:  62%|██████▏   | 38/61 [00:04<00:02,  8.56it/s]quant attn to fp8 ue8m0:  62%|██████▏   | 38/61 [00:04<00:02,  8.56it/s]quant attn to fp8 ue8m0:  62%|██████▏   | 38/61 [00:04<00:02,  8.55it/s]quant attn to fp8 ue8m0:  62%|██████▏   | 38/61 [00:04<00:02,  8.55it/s]quant attn to fp8 ue8m0:  64%|██████▍   | 39/61 [00:04<00:02,  8.93it/s]quant attn to fp8 ue8m0:  64%|██████▍   | 39/61 [00:04<00:02,  8.91it/s]quant attn to fp8 ue8m0:  64%|██████▍   | 39/61 [00:04<00:02,  8.90it/s]quant attn to fp8 ue8m0:  66%|██████▌   | 40/61 [00:04<00:02,  8.92it/s]quant attn to fp8 ue8m0:  66%|██████▌   | 40/61 [00:04<00:02,  8.91it/s]quant attn to fp8 ue8m0:  66%|██████▌   | 40/61 [00:04<00:02,  8.90it/s]quant attn to fp8 ue8m0:  66%|██████▌   | 40/61 [00:04<00:02,  8.91it/s]quant attn to fp8 ue8m0:  67%|██████▋   | 41/61 [00:04<00:02,  8.80it/s]quant attn to fp8 ue8m0:  67%|██████▋   | 41/61 [00:04<00:02,  8.78it/s]quant attn to fp8 ue8m0:  67%|██████▋   | 41/61 [00:04<00:02,  8.81it/s]quant attn to fp8 ue8m0:  67%|██████▋   | 41/61 [00:04<00:02,  8.79it/s]quant attn to fp8 ue8m0:  69%|██████▉   | 42/61 [00:04<00:02,  8.90it/s]quant attn to fp8 ue8m0:  69%|██████▉   | 42/61 [00:04<00:02,  8.88it/s]quant attn to fp8 ue8m0:  69%|██████▉   | 42/61 [00:04<00:02,  8.88it/s]quant attn to fp8 ue8m0:  69%|██████▉   | 42/61 [00:04<00:02,  8.88it/s]quant attn to fp8 ue8m0:  70%|███████   | 43/61 [00:04<00:02,  8.72it/s]quant attn to fp8 ue8m0:  70%|███████   | 43/61 [00:04<00:02,  8.72it/s]quant attn to fp8 ue8m0:  70%|███████   | 43/61 [00:04<00:02,  8.72it/s]quant attn to fp8 ue8m0:  70%|███████   | 43/61 [00:04<00:02,  8.73it/s]quant attn to fp8 ue8m0:  72%|███████▏  | 44/61 [00:04<00:01,  8.92it/s]quant attn to fp8 ue8m0:  72%|███████▏  | 44/61 [00:04<00:01,  8.89it/s]quant attn to fp8 ue8m0:  72%|███████▏  | 44/61 [00:04<00:01,  8.89it/s]quant attn to fp8 ue8m0:  72%|███████▏  | 44/61 [00:04<00:01,  8.89it/s]quant attn to fp8 ue8m0:  74%|███████▍  | 45/61 [00:04<00:01,  8.87it/s]quant attn to fp8 ue8m0:  74%|███████▍  | 45/61 [00:04<00:01,  8.87it/s]quant attn to fp8 ue8m0:  74%|███████▍  | 45/61 [00:04<00:01,  8.86it/s]quant attn to fp8 ue8m0:  74%|███████▍  | 45/61 [00:04<00:01,  8.85it/s]quant attn to fp8 ue8m0:  75%|███████▌  | 46/61 [00:05<00:01,  9.05it/s]quant attn to fp8 ue8m0:  75%|███████▌  | 46/61 [00:05<00:01,  9.05it/s]quant attn to fp8 ue8m0:  75%|███████▌  | 46/61 [00:05<00:01,  9.04it/s]quant attn to fp8 ue8m0:  75%|███████▌  | 46/61 [00:05<00:01,  9.05it/s]quant attn to fp8 ue8m0:  77%|███████▋  | 47/61 [00:05<00:01,  9.31it/s]quant attn to fp8 ue8m0:  79%|███████▊  | 48/61 [00:05<00:01,  9.45it/s]quant attn to fp8 ue8m0:  79%|███████▊  | 48/61 [00:05<00:01,  9.42it/s]quant attn to fp8 ue8m0:  79%|███████▊  | 48/61 [00:05<00:01,  9.43it/s]quant attn to fp8 ue8m0:  79%|███████▊  | 48/61 [00:05<00:01,  9.45it/s]quant attn to fp8 ue8m0:  80%|████████  | 49/61 [00:05<00:01,  9.51it/s]quant attn to fp8 ue8m0:  80%|████████  | 49/61 [00:05<00:01,  9.51it/s]quant attn to fp8 ue8m0:  80%|████████  | 49/61 [00:05<00:01,  9.51it/s]quant attn to fp8 ue8m0:  80%|████████  | 49/61 [00:05<00:01,  9.54it/s]quant attn to fp8 ue8m0:  82%|████████▏ | 50/61 [00:05<00:01,  9.60it/s]quant attn to fp8 ue8m0:  82%|████████▏ | 50/61 [00:05<00:01,  9.56it/s]quant attn to fp8 ue8m0:  82%|████████▏ | 50/61 [00:05<00:01,  9.54it/s]quant attn to fp8 ue8m0:  82%|████████▏ | 50/61 [00:05<00:01,  9.54it/s]quant attn to fp8 ue8m0:  84%|████████▎ | 51/61 [00:05<00:01,  9.51it/s]quant attn to fp8 ue8m0:  84%|████████▎ | 51/61 [00:05<00:01,  9.49it/s]quant attn to fp8 ue8m0:  84%|████████▎ | 51/61 [00:05<00:01,  9.49it/s]quant attn to fp8 ue8m0:  84%|████████▎ | 51/61 [00:05<00:01,  9.49it/s]quant attn to fp8 ue8m0:  85%|████████▌ | 52/61 [00:05<00:00,  9.57it/s]quant attn to fp8 ue8m0:  85%|████████▌ | 52/61 [00:05<00:00,  9.56it/s]quant attn to fp8 ue8m0:  85%|████████▌ | 52/61 [00:05<00:00,  9.57it/s]quant attn to fp8 ue8m0:  85%|████████▌ | 52/61 [00:05<00:00,  9.55it/s]quant attn to fp8 ue8m0:  87%|████████▋ | 53/61 [00:05<00:00,  9.63it/s]quant attn to fp8 ue8m0:  87%|████████▋ | 53/61 [00:05<00:00,  9.59it/s]quant attn to fp8 ue8m0:  87%|████████▋ | 53/61 [00:05<00:00,  9.57it/s]quant attn to fp8 ue8m0:  87%|████████▋ | 53/61 [00:05<00:00,  9.57it/s]quant attn to fp8 ue8m0:  89%|████████▊ | 54/61 [00:05<00:00,  9.49it/s]quant attn to fp8 ue8m0:  89%|████████▊ | 54/61 [00:05<00:00,  9.48it/s]quant attn to fp8 ue8m0:  89%|████████▊ | 54/61 [00:05<00:00,  9.48it/s]quant attn to fp8 ue8m0:  89%|████████▊ | 54/61 [00:05<00:00,  9.48it/s]quant attn to fp8 ue8m0:  90%|█████████ | 55/61 [00:06<00:00,  9.28it/s]quant attn to fp8 ue8m0:  90%|█████████ | 55/61 [00:06<00:00,  9.28it/s]quant attn to fp8 ue8m0:  90%|█████████ | 55/61 [00:06<00:00,  9.28it/s]quant attn to fp8 ue8m0:  90%|█████████ | 55/61 [00:06<00:00,  9.28it/s]quant attn to fp8 ue8m0:  92%|█████████▏| 56/61 [00:06<00:00,  9.01it/s]quant attn to fp8 ue8m0:  92%|█████████▏| 56/61 [00:06<00:00,  9.00it/s]quant attn to fp8 ue8m0:  92%|█████████▏| 56/61 [00:06<00:00,  9.00it/s]quant attn to fp8 ue8m0:  92%|█████████▏| 56/61 [00:06<00:00,  9.00it/s]quant attn to fp8 ue8m0:  93%|█████████▎| 57/61 [00:06<00:00,  9.28it/s]quant attn to fp8 ue8m0:  95%|█████████▌| 58/61 [00:06<00:00,  9.20it/s]quant attn to fp8 ue8m0:  95%|█████████▌| 58/61 [00:06<00:00,  9.20it/s]quant attn to fp8 ue8m0:  95%|█████████▌| 58/61 [00:06<00:00,  9.21it/s]quant attn to fp8 ue8m0:  95%|█████████▌| 58/61 [00:06<00:00,  9.21it/s]quant attn to fp8 ue8m0:  97%|█████████▋| 59/61 [00:06<00:00,  9.18it/s]quant attn to fp8 ue8m0:  97%|█████████▋| 59/61 [00:06<00:00,  9.18it/s]quant attn to fp8 ue8m0:  97%|█████████▋| 59/61 [00:06<00:00,  9.17it/s]quant attn to fp8 ue8m0:  97%|█████████▋| 59/61 [00:06<00:00,  9.16it/s]quant attn to fp8 ue8m0:  98%|█████████▊| 60/61 [00:06<00:00,  9.10it/s]quant attn to fp8 ue8m0:  98%|█████████▊| 60/61 [00:06<00:00,  9.10it/s]quant attn to fp8 ue8m0:  98%|█████████▊| 60/61 [00:06<00:00,  9.07it/s]quant attn to fp8 ue8m0:  98%|█████████▊| 60/61 [00:06<00:00,  9.08it/s]quant attn to fp8 ue8m0: 100%|██████████| 61/61 [00:06<00:00,  9.29it/s]quant attn to fp8 ue8m0: 100%|██████████| 61/61 [00:06<00:00,  9.29it/s]quant attn to fp8 ue8m0: 100%|██████████| 61/61 [00:06<00:00,  9.14it/s]quant attn to fp8 ue8m0: 100%|██████████| 61/61 [00:06<00:00,  9.14it/s]

quant attn to fp8 ue8m0: 100%|██████████| 61/61 [00:06<00:00,  9.27it/s]quant attn to fp8 ue8m0: 100%|██████████| 61/61 [00:06<00:00,  9.14it/s]
quant attn to fp8 ue8m0: 100%|██████████| 61/61 [00:06<00:00,  9.27it/s]quant attn to fp8 ue8m0: 100%|██████████| 61/61 [00:06<00:00,  9.14it/s]
[2025-11-30 07:44:19 DP33 TP33 EP33] Using FP8 KV cache but no scaling factors provided. Defaulting to scaling factors of 1.0. This may lead to less accurate results!
[2025-11-30 07:44:19 DP33 TP33 EP33] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=146.00 GB, mem usage=36.19 GB.
[2025-11-30 07:44:19 DP35 TP35 EP35] Using FP8 KV cache but no scaling factors provided. Defaulting to scaling factors of 1.0. This may lead to less accurate results!
[2025-11-30 07:44:19 DP35 TP35 EP35] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=146.00 GB, mem usage=36.18 GB.
[2025-11-30 07:44:19 DP34 TP34 EP34] Using FP8 KV cache but no scaling factors provided. Defaulting to scaling factors of 1.0. This may lead to less accurate results!
[2025-11-30 07:44:19 DP34 TP34 EP34] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=146.00 GB, mem usage=36.19 GB.
[2025-11-30 07:44:19 DP32 TP32 EP32] Using FP8 KV cache but no scaling factors provided. Defaulting to scaling factors of 1.0. This may lead to less accurate results!
[2025-11-30 07:44:19 DP32 TP32 EP32] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=146.00 GB, mem usage=36.18 GB.
[2025-11-30 07:44:24 DP35 TP35 EP35] KV Cache is allocated. #tokens: 3122368, KV size: 102.18 GB
[2025-11-30 07:44:24 DP33 TP33 EP33] KV Cache is allocated. #tokens: 3122368, KV size: 102.18 GB
[2025-11-30 07:44:24 DP32 TP32 EP32] KV Cache is allocated. #tokens: 3122368, KV size: 102.18 GB
[2025-11-30 07:44:24 DP33 TP33 EP33] Memory pool end. avail mem=43.00 GB
[2025-11-30 07:44:24 DP32 TP32 EP32] Memory pool end. avail mem=43.00 GB
[2025-11-30 07:44:24 DP35 TP35 EP35] Memory pool end. avail mem=43.00 GB
[2025-11-30 07:44:24 DP34 TP34 EP34] KV Cache is allocated. #tokens: 3122368, KV size: 102.18 GB
[2025-11-30 07:44:24 DP34 TP34 EP34] Memory pool end. avail mem=43.00 GB
[2025-11-30 07:44:24 DP33 TP33 EP33] Capture cuda graph begin. This can take up to several minutes. avail mem=42.43 GB
[2025-11-30 07:44:24 DP32 TP32 EP32] Capture cuda graph begin. This can take up to several minutes. avail mem=42.43 GB
[2025-11-30 07:44:24 DP35 TP35 EP35] Capture cuda graph begin. This can take up to several minutes. avail mem=42.43 GB
[2025-11-30 07:44:24 DP34 TP34 EP34] Capture cuda graph begin. This can take up to several minutes. avail mem=42.43 GB
WARN: device mlx5_0 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_0 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_1 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_0 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_0 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_1 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_4 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_1 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_1 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_4 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_5 cannot allocate buffer on the specified memory type. Skipping...

/sgl-workspace/nvshmem/src/host/transport/transport.cpp:nvshmemi_transport_init:282: init failed for transport: IBGDA
WARN: device mlx5_4 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_4 cannot allocate buffer on the specified memory type. Skipping...

WARN: device mlx5_5 cannot allocate buffer on the specified memory type. Skipping...

/sgl-workspace/nvshmem/src/host/transport/transport.cpp:nvshmemi_transport_init:282: init failed for transport: IBGDA
WARN: device mlx5_5 cannot allocate buffer on the specified memory type. Skipping...

/sgl-workspace/nvshmem/src/host/transport/transport.cpp:nvshmemi_transport_init:282: init failed for transport: IBGDA
WARN: device mlx5_5 cannot allocate buffer on the specified memory type. Skipping...

/sgl-workspace/nvshmem/src/host/transport/transport.cpp:nvshmemi_transport_init:282: init failed for transport: IBGDA
[2025-11-30 07:44:36 DP32 TP32 EP32] Capture cuda graph end. Time elapsed: 12.72 s. mem usage=31.12 GB. avail mem=11.32 GB.
[2025-11-30 07:44:36 DP35 TP35 EP35] Capture cuda graph end. Time elapsed: 12.75 s. mem usage=31.09 GB. avail mem=11.34 GB.
[2025-11-30 07:44:36 DP33 TP33 EP33] Capture cuda graph end. Time elapsed: 12.76 s. mem usage=31.09 GB. avail mem=11.34 GB.
[2025-11-30 07:44:36 DP34 TP34 EP34] Capture cuda graph end. Time elapsed: 12.78 s. mem usage=31.09 GB. avail mem=11.34 GB.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 07:44:38.149135 1801002 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.52.103.118 port: 12001
I1130 07:44:38.149145 1803490 transfer_engine.cpp:493] Metrics reporting thread started (interval: 5s)
I1130 07:44:38.149298 1801002 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.52.103.118:15176
I1130 07:44:38.149449 1801002 transfer_engine.cpp:185] Auto-discovering topology...
I1130 07:44:38.150472 1801002 transfer_engine.cpp:200] Topology discovery complete. Found 4 HCAs.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 07:44:38.154075 1801000 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.52.103.118 port: 12001
I1130 07:44:38.154093 1803492 transfer_engine.cpp:493] Metrics reporting thread started (interval: 5s)
I1130 07:44:38.154179 1801000 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.52.103.118:16202
I1130 07:44:38.154313 1801000 transfer_engine.cpp:185] Auto-discovering topology...
W1130 07:44:38.155052 1801002 nvlink_transport.cpp:385] Memory region 0xb4caea00 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.155102 1801002 nvlink_transport.cpp:385] Memory region 0xb6aaa940 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.155120 1801002 nvlink_transport.cpp:385] Memory region 0xb70aa9c0 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.155138 1801002 nvlink_transport.cpp:385] Memory region 0xb76aaa40 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.155153 1801002 nvlink_transport.cpp:385] Memory region 0xfff82cfb0040 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.155167 1801002 nvlink_transport.cpp:385] Memory region 0xfff774fb0040 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.155181 1801002 nvlink_transport.cpp:385] Memory region 0xb7caaac0 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.155195 1801002 nvlink_transport.cpp:385] Memory region 0xb82aab40 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.155208 1801002 nvlink_transport.cpp:385] Memory region 0xffe3cbff0040 is not allocated by cuMemCreate, but it can be used as local buffer
I1130 07:44:38.155267 1801000 transfer_engine.cpp:200] Topology discovery complete. Found 4 HCAs.
W1130 07:44:38.159415 1801000 nvlink_transport.cpp:385] Memory region 0x70bf0780 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.159471 1801000 nvlink_transport.cpp:385] Memory region 0x6f6f0680 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.159490 1801000 nvlink_transport.cpp:385] Memory region 0x68df0180 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.159505 1801000 nvlink_transport.cpp:385] Memory region 0x6a2f0280 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.159519 1801000 nvlink_transport.cpp:385] Memory region 0xaae1bd40 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.159533 1801000 nvlink_transport.cpp:385] Memory region 0xade1bdc0 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.159545 1801000 nvlink_transport.cpp:385] Memory region 0x678f0080 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.159557 1801000 nvlink_transport.cpp:385] Memory region 0xb0e1be40 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.159569 1801000 nvlink_transport.cpp:385] Memory region 0xffe3cbff0040 is not allocated by cuMemCreate, but it can be used as local buffer
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 07:44:38.210425 1801001 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.52.103.118 port: 12001
I1130 07:44:38.210448 1803502 transfer_engine.cpp:493] Metrics reporting thread started (interval: 5s)
I1130 07:44:38.210533 1801001 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.52.103.118:15834
I1130 07:44:38.210723 1801001 transfer_engine.cpp:185] Auto-discovering topology...
I1130 07:44:38.211650 1801001 transfer_engine.cpp:200] Topology discovery complete. Found 4 HCAs.
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 07:44:38.215266 1801003 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.52.103.118 port: 12001
I1130 07:44:38.215278 1803504 transfer_engine.cpp:493] Metrics reporting thread started (interval: 5s)
I1130 07:44:38.215355 1801003 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.52.103.118:16361
I1130 07:44:38.215523 1801003 transfer_engine.cpp:185] Auto-discovering topology...
W1130 07:44:38.215754 1801001 nvlink_transport.cpp:385] Memory region 0x7274e580 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.215790 1801001 nvlink_transport.cpp:385] Memory region 0x72d4e5c0 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.215803 1801001 nvlink_transport.cpp:385] Memory region 0x75454740 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.215814 1801001 nvlink_transport.cpp:385] Memory region 0x75a54780 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.215826 1801001 nvlink_transport.cpp:385] Memory region 0xfff8ccfd0040 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.215837 1801001 nvlink_transport.cpp:385] Memory region 0xfff8bcfd0040 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.215847 1801001 nvlink_transport.cpp:385] Memory region 0x760547c0 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.215857 1801001 nvlink_transport.cpp:385] Memory region 0x76654800 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.215866 1801001 nvlink_transport.cpp:385] Memory region 0xffe3cbff0040 is not allocated by cuMemCreate, but it can be used as local buffer
I1130 07:44:38.216287 1801003 transfer_engine.cpp:200] Topology discovery complete. Found 4 HCAs.
W1130 07:44:38.220288 1801003 nvlink_transport.cpp:385] Memory region 0x84380000 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.220326 1801003 nvlink_transport.cpp:385] Memory region 0x869dbec0 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.220338 1801003 nvlink_transport.cpp:385] Memory region 0x86fdbf40 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.220350 1801003 nvlink_transport.cpp:385] Memory region 0x87ab2d00 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.220361 1801003 nvlink_transport.cpp:385] Memory region 0x880b2d80 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.220372 1801003 nvlink_transport.cpp:385] Memory region 0x8b0b2e00 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.220381 1801003 nvlink_transport.cpp:385] Memory region 0x8e0b2e80 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.220391 1801003 nvlink_transport.cpp:385] Memory region 0x8e6b2f00 is not allocated by cuMemCreate, but it can be used as local buffer
W1130 07:44:38.220402 1801003 nvlink_transport.cpp:385] Memory region 0xffe3ebff0040 is not allocated by cuMemCreate, but it can be used as local buffer
[2025-11-30 07:44:38] Dummy health check server started in background thread at 0.0.0.0:30000
[2025-11-30 07:44:40 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.36, #queue-req: 0, 
[2025-11-30 07:44:40 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.36, #queue-req: 0, 
[2025-11-30 07:44:40 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.36, #queue-req: 0, 
[2025-11-30 07:44:40 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.36, #queue-req: 0, 
[2025-11-30 07:44:40 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 28.00, #queue-req: 0, 
[2025-11-30 07:44:40 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.97, #queue-req: 0, 
[2025-11-30 07:44:40 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.93, #queue-req: 0, 
[2025-11-30 07:44:40 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 28.09, #queue-req: 0, 
[2025-11-30 07:44:40 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.78, #queue-req: 0, 
[2025-11-30 07:44:40 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.76, #queue-req: 0, 
[2025-11-30 07:44:40 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.78, #queue-req: 0, 
[2025-11-30 07:44:40 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.77, #queue-req: 0, 
[2025-11-30 07:44:40 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.70, #queue-req: 0, 
[2025-11-30 07:44:40 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.71, #queue-req: 0, 
[2025-11-30 07:44:40 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.70, #queue-req: 0, 
[2025-11-30 07:44:40 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.71, #queue-req: 0, 
[2025-11-30 07:44:40 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.71, #queue-req: 0, 
[2025-11-30 07:44:40 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.71, #queue-req: 0, 
[2025-11-30 07:44:40 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.72, #queue-req: 0, 
[2025-11-30 07:44:40 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.71, #queue-req: 0, 
[2025-11-30 07:44:40 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.71, #queue-req: 0, 
[2025-11-30 07:44:40 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.71, #queue-req: 0, 
[2025-11-30 07:44:40 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.69, #queue-req: 0, 
[2025-11-30 07:44:40 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 64, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 27.69, #queue-req: 0, 
[2025-11-30 07:44:40 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 13.14, #queue-req: 0, 
[2025-11-30 07:44:40 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 13.13, #queue-req: 0, 
[2025-11-30 07:44:40 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 12.92, #queue-req: 0, 
[2025-11-30 07:44:40 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 12.92, #queue-req: 0, 
[2025-11-30 07:44:40 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 101.90, #queue-req: 0, 
[2025-11-30 07:44:40 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 115.90, #queue-req: 0, 
[2025-11-30 07:44:40 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 114.58, #queue-req: 0, 
[2025-11-30 07:44:40 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 99.20, #queue-req: 0, 
[2025-11-30 07:45:46 DP32 TP32 EP32] Cache flushed successfully!
[2025-11-30 07:45:46 DP33 TP33 EP33] Cache flushed successfully!
[2025-11-30 07:45:46 DP34 TP34 EP34] Cache flushed successfully!
[2025-11-30 07:45:46 DP35 TP35 EP35] Cache flushed successfully!
[2025-11-30 07:45:58 DP32 TP32 EP32] Decode batch, #running-req: 2, #token: 18432, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 16, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.03, #queue-req: 0, 
[2025-11-30 07:45:58 DP34 TP34 EP34] Decode batch, #running-req: 5, #token: 20480, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 17, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.06, #queue-req: 0, 
[2025-11-30 07:45:58 DP33 TP33 EP33] Decode batch, #running-req: 3, #token: 17408, token usage: 0.01, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 13, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.04, #queue-req: 0, 
[2025-11-30 07:45:58 DP35 TP35 EP35] Decode batch, #running-req: 6, #token: 17408, token usage: 0.01, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 12, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.08, #queue-req: 0, 
[2025-11-30 07:45:59 DP33 TP33 EP33] Decode batch, #running-req: 4, #token: 13312, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 13, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 4.95, #queue-req: 0, 
[2025-11-30 07:45:59 DP34 TP34 EP34] Decode batch, #running-req: 3, #token: 17408, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 17, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 3.72, #queue-req: 0, 
[2025-11-30 07:45:59 DP32 TP32 EP32] Decode batch, #running-req: 2, #token: 16384, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 16, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 2.48, #queue-req: 0, 
[2025-11-30 07:45:59 DP35 TP35 EP35] Decode batch, #running-req: 5, #token: 12288, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 12, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 6.19, #queue-req: 0, 
[2025-11-30 07:46:00 DP32 TP32 EP32] Decode batch, #running-req: 2, #token: 14336, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 14, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 2.29, #queue-req: 0, 
[2025-11-30 07:46:00 DP34 TP34 EP34] Decode batch, #running-req: 2, #token: 15360, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 15, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 2.29, #queue-req: 0, 
[2025-11-30 07:46:00 DP35 TP35 EP35] Decode batch, #running-req: 4, #token: 8192, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 8, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 4.58, #queue-req: 0, 
[2025-11-30 07:46:00 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 7168, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 7, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 7.38, #queue-req: 0, 
[2025-11-30 07:46:00 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 13312, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 13, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 7.38, #queue-req: 0, 
[2025-11-30 07:46:00 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 12288, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 12, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.99, #queue-req: 0, 
[2025-11-30 07:46:01 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 6144, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 3.67, #queue-req: 0, 
[2025-11-30 07:46:01 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 11264, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 11, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 3.67, #queue-req: 0, 
[2025-11-30 07:46:01 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 14336, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 14, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 2.45, #queue-req: 0, 
[2025-11-30 07:46:01 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 13312, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 13, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.49, #queue-req: 0, 
[2025-11-30 07:46:01 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 5120, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.41, #queue-req: 0, 
[2025-11-30 07:46:01 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 10240, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 10, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.29, #queue-req: 0, 
[2025-11-30 07:46:01 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 12288, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 12, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 6.97, #queue-req: 0, 
[2025-11-30 07:46:01 DP32 TP32 EP32] Decode batch, #running-req: 2, #token: 11264, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 11, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.84, #queue-req: 0, 
[2025-11-30 07:46:02 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 10240, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 10, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.34, #queue-req: 0, 
[2025-11-30 07:46:02 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 4096, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.17, #queue-req: 0, 
[2025-11-30 07:46:02 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 11264, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 11, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.26, #queue-req: 0, 
[2025-11-30 07:46:03 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 3072, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.32, #queue-req: 0, 
[2025-11-30 07:46:03 DP33 TP33 EP33] Decode batch, #running-req: 2, #token: 8192, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 8, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.29, #queue-req: 0, 
[2025-11-30 07:46:03 DP33 TP33 EP33] Decode batch, #running-req: 3, #token: 5120, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 25.58, #queue-req: 0, 
[2025-11-30 07:46:03 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 10240, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 10, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.20, #queue-req: 0, 
[2025-11-30 07:46:03 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 9216, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 9, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.14, #queue-req: 0, 
[2025-11-30 07:46:04 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 3072, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.30, #queue-req: 0, 
[2025-11-30 07:46:04 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 6144, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.30, #queue-req: 0, 
[2025-11-30 07:46:04 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 8192, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 7, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.69, #queue-req: 0, 
[2025-11-30 07:46:05 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 7168, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 7, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 12.32, #queue-req: 0, 
[2025-11-30 07:46:05 DP34 TP34 EP34] Decode batch, #running-req: 2, #token: 2048, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 2, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 2.48, #queue-req: 0, 
[2025-11-30 07:46:05 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 2048, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.42, #queue-req: 0, 
[2025-11-30 07:46:05 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 1024, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 12.21, #queue-req: 0, 
[2025-11-30 07:46:05 DP32 TP32 EP32] Decode batch, #running-req: 2, #token: 5120, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 2.39, #queue-req: 0, 
[2025-11-30 07:46:06 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.65, #queue-req: 0, 
[2025-11-30 07:46:06 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 2048, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.45, #queue-req: 0, 
[2025-11-30 07:46:06 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 1024, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 12.24, #queue-req: 0, 
[2025-11-30 07:46:06 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 2.75, #queue-req: 0, 
[2025-11-30 07:46:06 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.53, #queue-req: 0, 
[2025-11-30 07:46:07 DP32 TP32 EP32] Decode batch, #running-req: 2, #token: 1024, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.14, #queue-req: 0, 
[2025-11-30 07:46:07 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 18.55, #queue-req: 0, 
[2025-11-30 09:01:49 DP33 TP33 EP33] Cache flushed successfully!
[2025-11-30 09:01:49 DP35 TP35 EP35] Cache flushed successfully!
[2025-11-30 09:01:49 DP32 TP32 EP32] Cache flushed successfully!
[2025-11-30 09:01:49 DP34 TP34 EP34] Cache flushed successfully!
[2025-11-30 09:01:55 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 53248, token usage: 0.02, pre-allocated usage: 0.02, #prealloc-req: 0, #transfer-req: 26, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.00, #queue-req: 0, 
[2025-11-30 09:01:55 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 36864, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 18, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.00, #queue-req: 0, 
[2025-11-30 09:01:55 DP35 TP35 EP35] Decode batch, #running-req: 2, #token: 34816, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 17, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.00, #queue-req: 0, 
[2025-11-30 09:01:57 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 32768, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 16, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.78, #queue-req: 0, 
[2025-11-30 09:01:58 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 30720, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 15, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.26, #queue-req: 0, 
[2025-11-30 09:01:58 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 49152, token usage: 0.02, pre-allocated usage: 0.02, #prealloc-req: 0, #transfer-req: 24, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.39, #queue-req: 0, 
[2025-11-30 09:01:59 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 47104, token usage: 0.02, pre-allocated usage: 0.02, #prealloc-req: 0, #transfer-req: 23, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.60, #queue-req: 0, 
[2025-11-30 09:01:59 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 34816, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 17, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.26, #queue-req: 0, 
[2025-11-30 09:01:59 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 28672, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 14, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.57, #queue-req: 0, 
[2025-11-30 09:02:00 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 26624, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 13, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.32, #queue-req: 0, 
[2025-11-30 09:02:00 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 32768, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 16, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.00, #queue-req: 0, 
[2025-11-30 09:02:00 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 32768, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 16, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.26, #queue-req: 0, 
[2025-11-30 09:02:01 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 30720, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 15, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.15, #queue-req: 0, 
[2025-11-30 09:02:01 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 24576, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 12, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.15, #queue-req: 0, 
[2025-11-30 09:02:01 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 26624, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 13, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.15, #queue-req: 0, 
[2025-11-30 09:02:01 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 45056, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 22, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.59, #queue-req: 0, 
[2025-11-30 09:02:02 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 43008, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 21, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.17, #queue-req: 0, 
[2025-11-30 09:02:02 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 24576, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 12, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.17, #queue-req: 0, 
[2025-11-30 09:02:02 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 28672, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 14, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.08, #queue-req: 0, 
[2025-11-30 09:02:03 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 40960, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 20, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.34, #queue-req: 0, 
[2025-11-30 09:02:03 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 22528, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 11, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.34, #queue-req: 0, 
[2025-11-30 09:02:03 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 26624, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 13, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.28, #queue-req: 0, 
[2025-11-30 09:02:03 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 38912, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 19, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.13, #queue-req: 0, 
[2025-11-30 09:02:03 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 24576, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 12, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.23, #queue-req: 0, 
[2025-11-30 09:02:03 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 18432, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 9, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.13, #queue-req: 0, 
[2025-11-30 09:02:04 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 16384, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 8, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.20, #queue-req: 0, 
[2025-11-30 09:02:04 DP34 TP34 EP34] Decode batch, #running-req: 2, #token: 34816, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 17, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 2.30, #queue-req: 0, 
[2025-11-30 09:02:05 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 14336, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 7, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.27, #queue-req: 0, 
[2025-11-30 09:02:05 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 22528, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 11, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.60, #queue-req: 0, 
[2025-11-30 09:02:05 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 22528, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 11, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.24, #queue-req: 0, 
[2025-11-30 09:02:06 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 12288, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.20, #queue-req: 0, 
[2025-11-30 09:02:06 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 20480, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 10, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.16, #queue-req: 0, 
[2025-11-30 09:02:07 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 32768, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 15, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.41, #queue-req: 0, 
[2025-11-30 09:02:07 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 18432, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 9, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.23, #queue-req: 0, 
[2025-11-30 09:02:07 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 30720, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 15, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 13.48, #queue-req: 0, 
[2025-11-30 09:02:08 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 28672, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 14, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.25, #queue-req: 0, 
[2025-11-30 09:02:08 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 16384, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 8, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.20, #queue-req: 0, 
[2025-11-30 09:02:08 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 20480, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 10, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.40, #queue-req: 0, 
[2025-11-30 09:02:08 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 10240, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.57, #queue-req: 0, 
[2025-11-30 09:02:08 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 24576, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 12, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.16, #queue-req: 0, 
[2025-11-30 09:02:10 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 18432, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 9, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.40, #queue-req: 0, 
[2025-11-30 09:02:10 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 14336, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 7, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.40, #queue-req: 0, 
[2025-11-30 09:02:11 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 22528, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 11, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.40, #queue-req: 0, 
[2025-11-30 09:02:11 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 16384, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 8, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.19, #queue-req: 0, 
[2025-11-30 09:02:12 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 10240, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.59, #queue-req: 0, 
[2025-11-30 09:02:13 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 20480, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 10, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.59, #queue-req: 0, 
[2025-11-30 09:02:13 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 18432, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 9, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.25, #queue-req: 0, 
[2025-11-30 09:02:13 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 14336, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 7, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.40, #queue-req: 0, 
[2025-11-30 09:02:14 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 8192, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 4, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.58, #queue-req: 0, 
[2025-11-30 09:02:14 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 16384, token usage: 0.01, pre-allocated usage: 0.01, #prealloc-req: 0, #transfer-req: 8, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.14, #queue-req: 0, 
[2025-11-30 09:02:14 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 12288, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.19, #queue-req: 0, 
[2025-11-30 09:02:14 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 6144, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.24, #queue-req: 0, 
[2025-11-30 09:02:14 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 8192, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 4, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.15, #queue-req: 0, 
[2025-11-30 09:02:15 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 6144, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.14, #queue-req: 0, 
[2025-11-30 09:02:16 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 4096, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 2, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.60, #queue-req: 0, 
[2025-11-30 09:02:16 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 8192, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 4, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.60, #queue-req: 0, 
[2025-11-30 09:02:16 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 14336, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 7, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.58, #queue-req: 0, 
[2025-11-30 09:02:17 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 2048, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.26, #queue-req: 0, 
[2025-11-30 09:02:17 DP33 TP33 EP33] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 12.32, #queue-req: 0, 
[2025-11-30 09:02:17 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 12288, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.19, #queue-req: 0, 
[2025-11-30 09:02:18 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 4096, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 2, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.41, #queue-req: 0, 
[2025-11-30 09:02:18 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 10240, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.25, #queue-req: 0, 
[2025-11-30 09:02:18 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 6144, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.60, #queue-req: 0, 
[2025-11-30 09:02:20 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 2048, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.40, #queue-req: 0, 
[2025-11-30 09:02:20 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 8192, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 4, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.40, #queue-req: 0, 
[2025-11-30 09:02:21 DP32 TP32 EP32] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 2.77, #queue-req: 0, 
[2025-11-30 09:02:21 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 4096, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 0.31, #queue-req: 0, 
[2025-11-30 09:02:21 DP34 TP34 EP34] Decode batch, #running-req: 2, #token: 2048, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 2.72, #queue-req: 0, 
[2025-11-30 09:02:21 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 2048, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 13.73, #queue-req: 0, 
[2025-11-30 09:02:21 DP34 TP34 EP34] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 3.43, #queue-req: 0, 
[2025-11-30 09:02:22 DP35 TP35 EP35] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, cuda graph: True, gen throughput (token/s): 1.61, #queue-req: 0, 
